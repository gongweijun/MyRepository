{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4"
    },
    "colab": {
      "name": "03_初级神经网络之MNIST手写数字识别.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gongweijun/MyRepository/blob/master/03_%E5%88%9D%E7%BA%A7%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8BMNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "TmCvtKc9XsAK",
        "colab_type": "text"
      },
      "source": [
        "本WorkShop包含的代码可以在MNIST上训练完全连接的深层神经网络。 以前笔记本的主要变化是：\n",
        "*我们已经从线性分类器切换到深度神经网络。\n",
        "\n",
        "*我们添加了代码来显示TensorBoard中的图形和摘要数据。\n",
        "\n",
        "*我们正在使用AdamOptimizer而不是使用GradientDescentOptimizer。\n",
        "\n",
        "*我们正在使用Dropout。\n",
        "\n",
        "一个重要的要点：注意训练模型的代码与以前的Workshop相同，尽管模型更复杂。\n",
        "\n",
        "通过运行单元或者取消注释代码来尝试本Workshop\n",
        "\n",
        "当你完成这个笔记本，使用TensorBoard来查看结果。\n",
        "\n",
        "虽然这是一个简单的模型，但我们可以在MNIST上实现> 97％的准确度。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9_MHzg49E1Q",
        "colab_type": "text"
      },
      "source": [
        "# 新段落"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3qGvF_iXsAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lykx78K-XsAs",
        "colab_type": "text"
      },
      "source": [
        "### 初始化，数据准备"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCl-bqodXsAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l-M5nbrXsBE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义输出的位置\n",
        "LOGDIR = './graphs' "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Ifp6yhu8XsBW",
        "colab_type": "code",
        "outputId": "a10472e7-bbac-4c83-c2f5-d9514e9f458e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "# 获取数据\n",
        "mnist = input_data.read_data_sets('/tmp/data', one_hot=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-4-556c649dc745>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMPVXrm9XsB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 隐藏层的神经元数量\n",
        "HIDDEN1_SIZE = 500\n",
        "HIDDEN2_SIZE = 250\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "NUM_PIXELS = 28 * 28\n",
        "\n",
        "#  训练的次数\n",
        "#  每个训练批次的时间\n",
        "TRAIN_STEPS = 2000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "# 学习速率\n",
        "# notebook, and a new optimizer\n",
        "LEARNING_RATE = 0.001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpwdsZSBXsCH",
        "colab_type": "text"
      },
      "source": [
        "### 定义模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca43rYiDXsCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "with tf.name_scope('input'):\n",
        "    images = tf.placeholder(tf.float32, [None, NUM_PIXELS], name=\"pixels\")\n",
        "    labels = tf.placeholder(tf.float32, [None, NUM_CLASSES], name=\"labels\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwWgypQOXsCc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to create a fully connected layer\n",
        "def fc_layer(input, size_out, name=\"fc\", activation=None):\n",
        "    with tf.name_scope(name):\n",
        "        size_in = int(input.shape[1])\n",
        "        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"weights\")\n",
        "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"bias\")\n",
        "        wx_plus_b = tf.matmul(input, w) + b\n",
        "        if activation: return activation(wx_plus_b)\n",
        "        return wx_plus_b\n",
        "    \n",
        "# The way we initialize variables has an affect on how quickly \n",
        "# training converges. We may explore with different strategies later.\n",
        "# w = tf.Variable(tf.truncated_normal(shape=[size_in, size_out], stddev=1.0 / math.sqrt(float(size_in))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzTU0V3DXsCt",
        "colab_type": "code",
        "outputId": "8036c48f-d541-484c-ad14-c7c1256c797f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "# 定义模型\n",
        "\n",
        "# First, we'll create two fully connected layers, with ReLU activations\n",
        "#首先，我们定义俩层全连接层,并使用激励函数\n",
        "fc1 = fc_layer(images, HIDDEN1_SIZE, \"fc1\", activation=tf.nn.relu)\n",
        "fc2 = fc_layer(fc1, HIDDEN2_SIZE, \"fc2\", activation=tf.nn.relu)\n",
        "\n",
        "# Next, we'll apply Dropout to the second layer\n",
        "# This can help prevent overfitting, and I've added it here\n",
        "# for illustration. You can comment this out, if you like.\n",
        "\n",
        "dropped = tf.nn.dropout(fc2, keep_prob=0.9)\n",
        "\n",
        "# Finally, we'll calculate logists. This will be\n",
        "# the input to our Softmax function. Notice we \n",
        "# don't apply an activation at this layer.\n",
        "# If you've commented out the dropout layer,\n",
        "# switch the input here to 'fc2'.\n",
        "y = fc_layer(dropped, NUM_CLASSES, name=\"output\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-8-f89643e344df>:8: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmZq1G_7XsDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 定义损失函数与优化器\n",
        "with tf.name_scope(\"loss\"):\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y, labels=labels))\n",
        "    tf.summary.scalar('loss', loss)\n",
        "\n",
        "with tf.name_scope(\"optimizer\"):\n",
        "    # Whereas in the previous notebook we used a vanilla GradientDescentOptimizer\n",
        "    # here, we're using Adam. This is a single line of code change, and more\n",
        "    # importantly, TensorFlow will still automatically analyze our graph\n",
        "    # and determine how to adjust the variables to decrease the loss.\n",
        "    train = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r5rl5p9XsDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# \n",
        "with tf.name_scope(\"evaluation\"):\n",
        "    # these there lines are identical to the previous notebook.\n",
        "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(labels, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    tf.summary.scalar('accuracy', accuracy)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3WAH9KCXsD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set up logging.\n",
        "# We'll use a second FileWriter to summarize accuracy on\n",
        "# the test set. This will let us display it nicely in TensorBoard.\n",
        "train_writer = tf.summary.FileWriter(os.path.join(LOGDIR, \"train\"))\n",
        "train_writer.add_graph(sess.graph)\n",
        "test_writer = tf.summary.FileWriter(os.path.join(LOGDIR, \"test\"))\n",
        "summary_op = tf.summary.merge_all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mTnYggyXsEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIQRjWBFXsEX",
        "colab_type": "code",
        "outputId": "b21c8212-5002-483d-8d1b-f888c359c88f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "for step in range(TRAIN_STEPS):\n",
        "    batch_xs, batch_ys = mnist.train.next_batch(BATCH_SIZE)\n",
        "    summary_result, _ = sess.run([summary_op, train], \n",
        "                                    feed_dict={images: batch_xs, labels: batch_ys})\n",
        "\n",
        "    train_writer.add_summary(summary_result, step)\n",
        "    train_writer.add_run_metadata(tf.RunMetadata(), 'step%03d' % step)\n",
        "    \n",
        "    # calculate accuracy on the test set, every 100 steps.\n",
        "    # we're using the entire test set here, so this will be a bit slow\n",
        "    if step % 100 == 0:\n",
        "        summary_result, acc = sess.run([summary_op, accuracy], \n",
        "                                       feed_dict={images: mnist.test.images, \n",
        "                                                  labels: mnist.test.labels})\n",
        "        test_writer.add_summary(summary_result, step)\n",
        "        test_writer.add_run_metadata(tf.RunMetadata(), 'step%03d' % step)\n",
        "        print (\"test accuracy: %f at step %d\" % (acc, step))\n",
        "\n",
        "\n",
        "print(\"Accuracy %f\" % sess.run(accuracy, \n",
        "                               feed_dict={images: mnist.test.images,\n",
        "                                          labels: mnist.test.labels}))\n",
        "train_writer.close()\n",
        "test_writer.close()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test accuracy: 0.250200 at step 0\n",
            "test accuracy: 0.925100 at step 100\n",
            "test accuracy: 0.945600 at step 200\n",
            "test accuracy: 0.953600 at step 300\n",
            "test accuracy: 0.958300 at step 400\n",
            "test accuracy: 0.956900 at step 500\n",
            "test accuracy: 0.965700 at step 600\n",
            "test accuracy: 0.964600 at step 700\n",
            "test accuracy: 0.961800 at step 800\n",
            "test accuracy: 0.968000 at step 900\n",
            "test accuracy: 0.967500 at step 1000\n",
            "test accuracy: 0.972300 at step 1100\n",
            "test accuracy: 0.972400 at step 1200\n",
            "test accuracy: 0.970900 at step 1300\n",
            "test accuracy: 0.970300 at step 1400\n",
            "test accuracy: 0.971600 at step 1500\n",
            "test accuracy: 0.976000 at step 1600\n",
            "test accuracy: 0.973500 at step 1700\n",
            "test accuracy: 0.974700 at step 1800\n",
            "test accuracy: 0.976600 at step 1900\n",
            "Accuracy 0.977200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neeEzq4VXsEq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVXfe_-YXsEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3StkvG3XXsE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhEqecq9XsFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}